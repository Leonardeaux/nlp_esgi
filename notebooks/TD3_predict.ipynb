{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import warnings\n",
    "from transformers import TrainingArguments, Trainer, TrainerCallback, AutoModelForTokenClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 0.8992, -0.6409],\n",
       "         [ 1.3688, -1.3921],\n",
       "         [ 0.9500, -1.0284],\n",
       "         [ 0.6040, -0.7166],\n",
       "         [ 0.7609, -0.8519],\n",
       "         [ 0.8723, -0.6456]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"model_finetuned\", local_files_only=True, num_labels=2, ignore_mismatched_sizes=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "input_ids = tokenizer.encode(\"Hello Madame Michu\", return_tensors=\"pt\")\n",
    "\n",
    "model(input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
